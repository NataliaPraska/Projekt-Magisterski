\chapter{Podstawy teoretyczne i Tło technologiczne}

\section{Podstawy teoretyczne} 


\subsection{Definicje, pojęcia i klasyfikacje VR}
Aby uzasadnić potrzebe projektowania interfejsów i interakcji w grach VR w odmienny sposób niż w przypadku gier 2D czy 3D, należy najpierw zrozumieć czym jest tak naprawde VR. 
W niniejszej pracy przyjęto ujęcie rzeczywistości wirtualnej zaproponowane w książce The VR Book autorstwa Jasona Jeralda. Rzeczywistość wirtualna rozumiana jest jako w pełni sztuczne, cyfrowe otoczenie generowane komputerowo, które wywołuje u użytkownika poczucie przebywania w innym miejscu lub świecie oraz umożliwia mu bezpośrednie doświadczanie i interakcję w sposób zbliżony do kontaktu z rzeczywistym środowiskiem (Jerald, The VR Book). Przyjęcie tej definicji było argumentowane tym, że zawiera ona kluczowe pojęcia immersji i obecności, które stanowią podstawowe kryteria oceny jakości doświadczeń w grach VR oraz będą mieć bezpośredni wpływ na sposób projektowania interfejsów i interakcji. W odróznieniu od tradycyjnych gier komputerowych oraz aplikacji, technologia ta nie ogranicza się tylko do obserwowania obrazu na ekranie lecz zakłada pełne zaangażowanie użytkownika. 

Dzięki specjalistycznym urządzeniom, takim jak gogle czy kontrolery ruchu, możliwe staje się obserwowanie i oddziaływanie na generowane wirtualnie obiekty w czasie rzeczywistym. Rozwiązania z zakresu VR wykorzystują zaawansowane techniki renderowania grafiki, precyzyjnie śledzą ruch głowy i dłoni, a także uwzględniają dźwięk przestrzenny. Może angażować nie tylko słuch i wzrok ale również dotyk poprzez kontrolery haptyczne. Wirtualna rzeczywistość odziałowywuje na różne \textbf{zmysły}, aby maksymalnie zwiększyć zanurzenie użytkownika i osiągnięcie wrażenia, że świat wirtualny jest prawdziwy a użytkownik jest w nim naprawdę obecny. 

Do opisu doświadczeń w grach często stosowane jest pojęcie immersja oraz obecność. Słowa te są czesto mylnie stosowane jako synonimy choć odnoszą się do rożnych aspektów VR. Różnice między tymi pojęciami dość trafnie opisał Jerald w swojej książce book. Zaznacza on, że Imersja nawiązuje do cech VR, do tego w jak mocno oddziałowują na na zmysły użytkownika. Natomiast obecność odnosi się do subiektywnego wrażenia i odczucia użytkownika że znajduje się w świecie wirtualnym. Rozóżnienie to ma ogromne znaczenie dla projektowania interfejsu w grach VR, ponieważ wysoki poziom immersji technicznej nie gwarantuje jeszcze poczucia obecności. W kontekście gier VR pojęcia te nabierają szczególnego znaczenia, ponieważ są bezpośrednio zależne od sposobu i jakości zaprojektowania całego doświadczenia w grze.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/vr_example.jpg}
    \caption{Symulator medyczny służący do szkolenia lekarzy}
    \label{vr_example}
\end{figure}\textbf{}


\subsection{Ergonomia, percepcja i ograniczenia użytkownika}

W grach komputerowych czy aplikacjach rzadko zdarza się aby użytkownik odczuwał dyskomfort fizyczny. VR angażuje urzytkownika intensywniej niż tradycyjne rozgrywki na komputer i pozwala użytkownikowi na pełne zanurzenie się w rozgrywkę. Tworzenie treści do tego środowiska wymaga uwzględnienia ograniczeń percepcyjnych i fizjologicznych człowieka. Jednym z efektów braku takiego podejścia jest wystąpienie objawów choroby symulatorowej (VR sickness). Objawia się najczęściej mdłościami, zawrotami głowy czy ogólna dezorientacją. Według ksiązki 3D User Interfaces: Theory and Practice (book) (3D user Interfaces Theory and Practice) jest ona spowodowana niespójnością pomiędzy tym, co użytkownik widzi czyli ruch w świecie wirtualnym, a tym, co odczuwa jego ciało czyli brak fizycznego ruchu. Z tego wzgledu bardzo istotne jest tempo interakcji, ograniczenie gwałtwonych zmian perspektywy i widoku oraz przewidywalność zachowań systemu ponieważ to miedzy innymi one będą miały wpływ na długie i komfortowe korzystanie z urządzenia. 

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/VRSICK.png}
    \caption{VR sickness}
    \label{unity_engine_example}
\end{figure}
(3D user Interfaces Theory and Practice)


Zaangażowanie całego ciała w przypadku gier VR mocno angażuje odbiorców ale nakłada również pewne ograniczenia na projektantów. Jednym z nich jest to że niewłasciwe ułożenie obiektów na scenie lub wymuszenie utrzymywania dłoni w nienaturalnej pozycji przez dłuższy czas może prowadzić do szybkiego zmęczenia. Z tego powody należy uwzględnić naturalny zakres ruchu człowieka aby wszelkiego rodzaju interakcje mogły być wykonywane bez nadmiernego wysiłku fizycznego.  (book) jerald

Problematycznym może okazać się samo umieszczenie obiektów interaktywnych w środowisko wirtualnym. Pole widzenia w googlach jest ograniczone nie tylko ze względu na konstrukcje urządzeni ale również naszych indywidualnych cech anatomicznych jak rozstaw źrenic. Ma to istotny wpływ na odbiór interfejsu i rozmieszczenie informacji w przestrzeni. Jak wykazują badania  Sauer i współpracowników (2022),  article (Assessment of consumer VR). pole widzenia jakie deklarują producenci zestawów VR jest inne niż rzeczywistosci a jego zakres zależy fizjologi odbiorcy. Umieszczenie kluczowych elementów poza zakresem widzialnym będzie prowadził do ich przeoczenia lub wymuszenia zbędnych ruchów i w rezultacie zmęczenia lub irytacji. 
%Ten fragment cały ma informacje z dwoch ksiazek i jednego artykulu i nie wiem jak cytować  (Jerald, 2015; LaViola et al., 2017; Sauer et al., 2022).
Z tego względu należy stosować nie tylko teoretyczne założenia techniczne podane przez producenta ale również empiryczne ograniczenia odbiorców.

Aby ograniczyć wcześniej wspomniane zmęczenie i zmniejszyć przeciążenie poznawcze podczas projektowania należy uwzglednić również czas trwania sesji i intensywność bodzców. Użytkownik podczas długotrwałego korzystania z vr jest mocno zaangażowany nie tylko sensorycznie ale również fizycznie. Sprawia to że nawet po krótkiej sesji może czuć sie wyczerpany. Dzieje się to znacznie szybciej niż w przypadku gier na komputer czy konsole. Z tego powodu zaleca się projektowanie doświadczeń w taki sposób by umożliwić odpoczynek użytkownika. warto również wprowadzenić możliwości dostosowania ustawień takich jak automatyczne trzymanie obiektu czy wysokość kamery. Uwzględnienie tych czynników pozwala ograniczyć negatywne skutki długotrwałego użytkowania VR oraz sprzyja utrzymaniu pozytywnego odbioru doświadczenia przez użytkownika.

 
\subsection{Typy interfejsów VR (digetyczne, niedigetyczne, przestrzenne, statusowe)}

Projektowanie interfejsu do VR może odbywać się na różne sposoby, różniące się stopniem integracji z wirtualnym środowiskiem i tym jak prezentowane są istotne informacje. Aby odpowiednio przygotować się do projektowania, konieczna będzie analiza rozwiązań stosowanych w istniejących już grach i aplikacjach. Twórcy gier podejmują różne decyzje dotyczące formy interfejsu użytkownika, wynikające z odmiennych priorytetów projektowych, od dążenia do maksymalnej immersji poprzez silną integrację interfejsu ze światem gry, po wykorzystanie bardziej tradycyjnych rozwiązań w postaci paneli menu i lewitujących w przestrzeni wirtualnej elementów interfejsu. W pierwszej kolejności warto poznać podstawowe rodzaje interfejsów oraz ich charakterystykę. Pozwala to lepiej zrozumieć, w jakich sytuacjach i w jakim celu poszczególne rozwiązania są wykorzystywane. W niniejszej analizie przyjęto podział interfejsów na cztery główne typy:
Interfejs jako część świata gry, Klasyczny panel menu (Non-diegetic UI), Interfejs przestrzenny oraz Meta.
Pierwszy rodzaj polega na wpleceniu interfejsu w elementy już istniejące w świecie wirtualnym, użytkownik żeby go zobaczyć musi fizycznie skierować głowę na dany element. Drugi z kolei wykorzystuje tradycyjny panel menu, ktory możemy spotkać na stronach internetowych czy w grach na komputer. Elementy interfejsu nie są częścią świata gry a sam panel jest nakładką na widok użytkownika. Kolejne podejście to interfejs przestrzenny, jest on połączeniem digetycznych i niedigetycznych.  Stanowi często część środowiska wirtualnego i jest w nim wyświtlany ale nie jest widoczny przez postacie. Ostatni typ to Meta, któy służy do reprezentacji statusu naszej postaci nie pojawiając się jednocześnie w świecie gry
%Interfejs diegetyczny – wpleciony w świat gry; użytkownik musi fizycznie spojrzeć na dany obiekt, aby zobaczyć informacje (np. zegarek na nadgarstku postaci).
%Interfejs niediegetyczny (klasyczny panel menu) – elementy UI nie są częścią świata gry, lecz nakładką na widok użytkownika (np. menu pauzy).
%Interfejs przestrzenny – zakotwiczony w przestrzeni wirtualnej, ale niekoniecznie istniejący w świecie gry z perspektywy postaci (np. menu przypięte do ściany).
%Interfejs statusowy (HUD) – reprezentuje stan postaci (np. poziom zdrowia), nie pojawiając się fizycznie w świecie gry.

%Godbold, Ashley. Mastering UI Development with Unity: Develop Engaging and Immersive User Interfaces with Unity. Niemcy: Packt Publishing, 2024.


\subsection{Opis typowych sposobów interakcji w VR}

Interakcje VR obejmują wszystkie działania, jakie użytkownik może wykonywać w wirtualnym świecie. Nie są to wyłącznie interakcje z obiektami, ale również sposoby przemieszczania się użytkownika oraz sterowanie działaniem systemu. Charakter i jakość tych działań mają bezpośredni wpływ na odbiór całego doświadczenia oraz poziom zaangażowania użytkownika.

Jak zauważa Steven Antonio, autor książki Enhancing Virtual Reality Experiences with Unity 2022, tworzenie realistycznych interakcji w VR ma fundamentalne znaczenie dla zapewnienia niezapomnianych, wciągających doświadczeń. Stwierdzenie to jest częściowo trafne, o ile przez realizm rozumiemy spójność bodźców symulacji z mechanizmami percepcji użytkownika. To właśnie ta zgodność determinuje, czy u odbiorcy wystąpią objawy choroby VR.

Interakcje VR można grupować i dzielić na różne sposoby, w zależności od przyjętej perspektywy. W książce The VR Book Jerald proponuje podział interakcji na pięć głównych wzorców: wzorce selekcji, wzorce manipulacji, wzorce kontroli punktu widzenia, wzorce kontroli pośredniej oraz wzorce złożone. Takie podejście koncentruje się głównie na sposobie realizacji interakcji, opisując powtarzalne schematy projektowe wraz z ich zaletami, ograniczeniami oraz przykładami zastosowań. Z kolei 3D User Interfaces: Theory and Practice rozważa interakcje z perspektywy zadań wykonywanych przez użytkownika w środowisku wirtualnym, odpowiadając na pytanie, co użytkownik może zrobić w VR.
W niniejszej pracy zastosowano podejście zorientowane na użytkownika, dlatego jako główny przyjęto podział zaproponowany przez LaViolę, który pozwala analizować interakcje VR w odniesieniu do faktycznych działań użytkownika i ich wpływu na komfort oraz użyteczność doświadczenia. W tym ujęciu wyróżnione zostały cztery główne kategorie interakcji.

Autor książki 3D User Interfaces: Theory and Practice jako pierwszy typ interakcji wyróżnia selekcję i manipulację. Zadania te są ze sobą ściśle powiązane i w środowisku wirtualnym rzadko występują oddzielnie.Selekcja w kontekście VR polega na wskazywaniu lub identyfikacji obiektu, przy czym może być realizowana za pomocą różnych technik interakcji, takich jak użycie rąk, promienia wskazującego czy kierunku spojrzenia. Jej podstawową funkcją jest określenie, który element środowiska staje się aktualnym celem dalszych działań użytkownika. Z kolei manipulacja obejmuje czynności, jakie użytkownik może wykonać na już wybranym obiekcie. Może to być zmiana jego położenia, orientacji lub wielkości. Selekcja stanowi etap wstępny do manipulacji i jest warunkiem koniecznym do jej rozpoczęcia.

Przemieszczanie w środowiskach wirtualnych odnosi się do działań użytkownika związanych z poruszaniem się oraz orientacją w przestrzeni wirtualnej. Składa się ono z dwóch wzajemnie powiązanych komponentów. Pierwszym z nich jest wayfinding, będący aspektem poznawczym nawigacji, odpowiedzialnym za rozumienie przestrzeni, identyfikowanie punktów orientacyjnych oraz planowanie trasy. Drugim jest travel, stanowiący aspekt motoryczny nawigacji, obejmujący fizyczną realizację ruchu oraz sterowanie punktem widzenia. Skuteczna nawigacja wymaga spójnego współdziałania obu tych elementów, ponieważ nawet najbardziej intuicyjne techniki przemieszczania tracą użyteczność bez odpowiedniej orientacji przestrzennej użytkownika.

Kontrola systemu w środowiskach trójwymiarowych i wirtualnej rzeczywistości stanowi typ interakcji polegający na jawnym wydawaniu poleceń systemowi, takich jak uruchamianie funkcji, zmiana trybu interakcji lub modyfikacja stanu systemu. W przeciwieństwie do selekcji, manipulacji czy nawigacji użytkownik określa jedynie cel działania, pozostawiając sposób jego realizacji po stronie systemu. Nie jest ona główną formą aktywności użytkownika, lecz pełni rolę warstwy sterującej przebiegiem pozostałych interakcji. Projektowanie tych mechanizmów w VR jest szczególnie wymagające, ponieważ konwencjonalne rozwiązania 2D nie przenoszą się bezpośrednio do środowisk immersyjnych, które opierają się na wejściu sześciostopniowym oraz odmiennych uwarunkowaniach percepcyjnych.


Taki sposób klasyfikacji interakcji pozwala na uporządkowanie możliwych działań użytkownika w środowisku VR. Umożliwia on dalsze rozważania nad projektowaniem interfejsów i interakcji w wirtualnej rzeczywistości z perspektywy faktycznych działań wykonywanych przez użytkownika.

\subsection{Klasyczne zasady UX w kontekście środowisk VR}

Chociaż większość podstawowych zasad UX designu takich jak hierarchia wizualna, zasady Gestalt, spójność, czytelne affordance oraz informacje zwrotne są  uznawane za uniwersalane to projektowanie interfejsu użytkownika w oparciu o nie wymaga od projektanta innego podejścia. Wynika to z odmienności systemu VR od innych technologii, takich jak aplikacje mobilne, aplikacje desktopowe czy strony internetowe, w których interakcja z systemem odbywa się za pośrednictwem płaskiego ekranu oraz urządzeń wejścia, takich jak mysz, klawiatura czy ekran dotykowy.
W wirtualnej rzeczywistości interakcje odbywają sie w przestrzeni trójwymiarowej i wymagają aktywnosci ruchowej użytkownnika. Z tego powodu konieczne jest odpowiednie zastosowanie klasycznych zasad w sposób umożliwiający użytkownikom komfortową, intuicyjną oraz płynną interakcję z systemem.

Jedną z największych różnic w stosowaniu zasad UX w VR jest sposób nawigacji i poruszania się po środowisku wirtualnym. W tradycyjnych interfejsach użytkownik przemieszcza się po aplikacji za pomocą kliknięć, przewijania lub naciskania przycisków. W wirtualnej rzeczywistości nawigacja opiera się w dużej mierze na naturalnych ruchach użytkownika oraz mechanizmach lokomocji, takich jak teleportacja. Zmiana ta wpływa bezpośrednio na sposób projektowania hierarchii informacji oraz rozmieszczenia elementów interfejsu w przestrzeni.

Następna równie ważna różnica to \textbf{Interakcja w przestrzeni 3D}. W tradycyjnych interfejsach użytkownik wchodzi w interakcje z płaskimi, dwuwymiarowymi elementami na ekranie. W VR interakcje odbywają się w sposób bezpośredni i możliwe jest manipulowanie obiektami w sposób zbliżony do rzeczywistych czynności, takich jak chwytanie, obracanie czy przesuwanie elementów tak jakby były on prawdziwe. Taki sposób interakcji wzmacnia immersję, lecz jednocześnie wymaga szczególnej dbałości o czytelne affordance oraz natychmiastową informację zwrotną, aby użytkownik mógł poprawnie interpretować skutki swoich działań.

Adaptacja klasycznych zasad UX do środowiska VR wiąże się również z koniecznością unikania określonych rozwiązań projektowych, które mogą negatywnie wpływać na komfort i odbiór doświadczenia. Nadmierna liczba elementów interfejsu prowadzi do przeciążenia poznawczego i zaburza immersję, dlatego projektowanie powinno opierać się na minimalizmie oraz koncentracji na kluczowych funkcjach, przy jednoczesnym ukrywaniu lub eliminowaniu elementów drugorzędnych. Równie istotne jest unikanie nagłych zmian perspektywy i gwałtownych ruchów kamery, które mogą powodować dezorientację, zawroty głowy, a w skrajnych przypadkach także mdłości. Ruch w środowisku wirtualnym powinien być płynny i przewidywalny, naśladując naturalne ruchy głowy użytkownika oraz wspierany przez stopniowe przejścia i animacje. Ponadto brak spójnych i powtarzalnych schematów interakcji może prowadzić do frustracji użytkowników; stosowanie ujednoliconych rozwiązań tam, gdzie jest to możliwe, ułatwia adaptację do środowiska VR, skraca czas nauki obsługi systemu oraz pozytywnie wpływa na ogólne doświadczenie użytkownika (Swink, Game Feel).


\section{Tło technologiczne VR} 

Kluczowym etapem projektowania tej pracy był wybór odpowiednich narzędzi umożliwiających prototypownie, implementację oraz testowanie interfejsu w środowisku VR. Wybór używanej technologii jest kluczowy, aby zapewnić wysoką jakość doświadczeń użytkownika oraz zachować efektywność samego procesu projektowania.


\subsection{Silniki gier i środowiska VR (Unity, Unreal, Godot)}

\textit{Unity} to jeden z najpopularniejszych wieloplatformowych silników do tworzenia gier wideo oraz interaktywnych aplikacji. Umożliwia zaawansowaną obsługę grafiki i fizyki, a w samym edytorze udostępniono rozbudowany zestaw narzędzi do projektowania scen, animacji i efektów graficznych \ref{unity_engine_example}. Proces programowania odbywa się przy użyciu języka \textit{C\#}.

W Unity dodano również wsparcie dla wirtualnej oraz rozszerzonej rzeczywistości, co przekłada się na szerokie zastosowanie tej technologii w szkoleniach, symulacjach czy działaniach marketingowych. Oprócz możliwości tworzenia zaawansowanych pod względem wizualnym scen, istotna jest też opcja łatwej integracji gotowych wtyczek obsługujących urządzenia AR i VR od różnych producentów. Rozbudowany system oświetlenia oraz post-processingu zapewnia szeroki wachlarz opcji i umożliwia dostosowanie grafiki pod dedykowane urządzenia, dzięki czemu można uzyskać zadowalającą jakość i odpowiednią optymalizację na urządzenia mobilne oraz wysoce realistyczną grafikę na komputerach osobistych.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/unity.png}
    \caption{Przykładowy wygląd edytora Unity}
    \label{unity_engine_example}
\end{figure}

Regularne aktualizacje silnika rozszerzają jego funkcjonalność i dodają nowe rozwiązania, takie jak obsługa ray tracingu, DLSS oraz nowe narzędzia. Stały rozwój sprawia, że Unity zachowuje elastyczność w obliczu zmieniających się potrzeb rynku, a jego wszechstronność umożliwia realizację nawet najbardziej rozbudowanych koncepcji interaktywnych.

Społeczność skupiona wokół tego silnika udostępnia liczne materiały edukacyjne w postaci kursów i filmów, co znacząco obniża poziom wejścia, przyspiesza naukę oraz ułatwia rozwiązywanie ewentualnych problemów technicznych. Dokumentacja silnika jest regularnie rozwijana, a oficjalny sklep \textit{Asset Store} zapewnia dostęp do bardzo dużej ilości bezpłatnych oraz płatnych pakietów, obejmujących zasoby takie jak modele, tekstury i dźwięki oraz dodatkowe użyteczne narzędzia wraz z całymi gotowymi systemami ułatwiającymi stworzenie projektu i pozwalającymi ograniczyć koszty produkcji.


\subsection{Biblioteki i frameworki VR (XR Toolkit, OpenXR, SteamVR)}

\subsection{Narzędzia do projektowania interfejsów (Figma, Blender)}

Figma to podstawowe narzędzie służące do projektowania interfejsów użytkownika, jednocześnie umożliwia tworzenie interaktywnych klikalnych prototypów aplikacji. Jest to aktualnie jedno z najbardziej popularnych i bezpłatnych narzędzi w branży UX/UI. W projekcie Figma zostanie wykorzystana do stworzenia wstępnych projektów i prototypów interfejsów, a następnie do przetestowania rożnych układów elementów interfejsu. 

\subsection{Narzędzia do analizy UX/UI (Google Forms, UEQ, SUS)}

Gogle VR to urządzenia, które całkowicie zasłaniają pole widzenia i wyświetlają przez użytkownikiem dwa identyczne, ale nieco przesunięte od siebie obrazy, które nałożone na siebie przez mózg dają wrażenie głębi. Wewnątrz gogli umieszczone są specjalne czujniki takie jak żyroskop, kamery i inne śledzące położenie i ruch głowy w przestrzeni. Dzięki temu użytkownik obracając głową faktycznie rozgląda się w przestrzeni wirtualnej obracając kamerą gracza.

Oprócz gogli istotne są również specjalne kontrolery zakładane na dłonie. Dzięki nim możliwa jest interakcja z wirtualnym otoczeniem, a specjalne czujniki i przyciski wykrywają pozycje palców i pozwalają określić, czy gracz w tej chwili próbuje złapać przedmiot. Całość wraz z systemem śledzenia pozycji dłoni pozwala dowolnie sięgać w różnych kierunkach, co pozwala mieć wpływ na obiekty w aplikacji. Gracz może na przykład chwycić przedmiot i rzucić nim, co pozwoli wywołać kolejne symulacje w fizyce.

Oprócz tego istnieje wiele różnych dodatków rozszerzających możliwości wirtualnej rzeczywistości, jak specjalne kombinezony monitorujących ruch oraz umożliwiających odczuwanie na skórze poprzez elektrostymulację nerwów i mięśni lub kapsuły, w których użytkownik ma możliwość skakania oraz poruszania się w dowolny sposób bez ryzyka, że uszkodzi coś w pokoju.

2.9. Sprzęt i konfiguracja testowa

